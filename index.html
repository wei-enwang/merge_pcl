
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Building a pointcloud library of objects">
    <meta name="author" content="Wei-En Wang">

    <title>Building a pointcloud library of objects</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Building a pointcloud library of objects</h2>
<!--            <p class="abstract">An interpretable, data-efficient, and scalable neural scene representation.</p>-->
    <hr>
    <p class="authors">
        <h4>Wei-En Wang</a>
    </p>
    <!-- <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="">Paper</a>
        <a class="btn btn-primary" href="">Colab Notebook</a>
        <a class="btn btn-primary" href="">Code</a>
        <a class="btn btn-primary" href="">Data</a>
    </div> -->
</div>

<div class="container">
    <div class="section">
        <h2>Introduction</h2>
        <hr>
        <p>
            In this project, I adopted an improved version of the <i>Iterative Closest Point</i> algorithm to merge the pointclouds of an object obtained from different perspectives. 
        </p>
    </div>
    <div class="section">
        <h2>Process of merging clouds</h2>
        <hr>
        <p>
            A Siren that maps 2D pixel coordinates to a color may be used to parameterize images. Here, we supervise Siren
            directly with ground-truth pixel values. Siren not only fits the image with a 10 dB higher PSNR and in significantly
            fewer iterations than all baseline architectures, but is also the only MLP that accurately represents the first-
            and second order derivatives of the image.
        </p>
    </div>

    <div class="section">
        <h2>Demo Video</h2>
        <hr>
        <p>
            The video below shows the process that our algorithm builds up the pointcloud of some objects.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="50%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/cat_comparison_label.mp4" type="video/mp4">
                </video>
            </div>
            <div class="col justify-content-center text-center">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/bikes_comparison_label.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </div>


    <div class="section">
        <h2>Pointcloud building process<br>
            Interactive 3D mesh Viewer - Use Your Mouse to Observe</h2>
        <hr>
        <p>
            The software <a href="https://www.meshlab.net/">meshlab</a> is used to generate mesh files from the pointclouds. We computed the normals for the clouds and used the Ball-Pivoting Algorithm to produce the final meshes.
        </p>
        <div class="container">
            <div class="row align-items-center">
                <div class="col-md-4 padding-0 canvas-row">
                    <h4>Watch - first scene</h4>
                    <model-viewer
                            alt="Room Siren"
                            src="./src/clouds/6_first.glb"
                            style="width: 100%; height:300px; background-color: #404040"
                            exposure=".8"
                            camera-controls>
                    </model-viewer>
                </div>
                <div class="col-md-4 padding-0 canvas-row">
                    <h4>Watch - after 5 scenes</h4>
                    <model-viewer
                            alt="Room ReLU"
                            src="./src/clouds/6_final.glb"
                            style="width: 100%; height: 300px; background-color: #404040"
                            exposure=".8"
                            camera-controls>
                    </model-viewer>
                </div>
                <div class="col-md-4 padding-0 canvas-row">
                    <h4>Watch - final scene</h4>
                    <model-viewer
                            alt="Room ReLU"
                            src="./src/clouds/7_first.glb"
                            style="width: 100%; height: 300px; background-color: #404040"
                            exposure=".8"
                            camera-controls>
                    </model-viewer>
                </div>
            </div>
            <div class="row align-items-center">
                <div class="col-md-4 padding-0 canvas-row">
                    <h4>Statue - Siren</h4>
                    <model-viewer
                            alt="Statue Siren"
                            src="img/statue_siren.glb"
                            style="width: 100%; height: 600px; background-color: #404040"
                            exposure=".8"
                            camera-orbit="0deg 75deg 20%"
                            auto-rotate
                            camera-controls>
                    </model-viewer>
                </div>
                <div class="col-md-4 padding-0 canvas-row">
                    <h4>Statue - ReLU Pos. Enc.</h4>
                    <model-viewer
                            alt="Statue Positional Encoding"
                            src="img/statue_relu_pe.glb"
                            style="width: 100%; height: 600px; background-color: #404040"
                            exposure=".8"
                            camera-orbit="0deg 75deg 20%"
                            auto-rotate
                            camera-controls>
                    </model-viewer>
                </div>
                <div class="col-md-4 padding-0 canvas-row">
                    <h4>Statue - ReLU</h4>
                    <model-viewer
                            alt="Statue ReLU"
                            src="img/statue_relu.glb"
                            style="width: 100%; height: 600px; background-color: #404040"
                            exposure=".8"
                            camera-orbit="0deg 75deg 20%"
                            auto-rotate
                            camera-controls>
                    </model-viewer>
                </div>
            </div>
        </div>

        <!-- Loads <model-viewer> for modern browsers: -->
        <script type="module"
                src="https://unpkg.com/@google/model-viewer/dist/model-viewer.js">
        </script>
    </div>

    <div class="section">
        <h2>Solving the Helmholtz equation</h2>
        <hr>
        <p>
            Here, we use Siren to solve the <a href="https://en.wikipedia.org/wiki/Helmholtz_equation">inhomogeneous Helmholtz equation</a>.
            ReLU- and Tanh-based architectures fail entirely to converge to a solution.
        </p>
        <div class="gif">
            <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                <source src="img/helmholtz_convergence_video_pad_label.mp4" type="video/mp4">
            </video>
        </div>
    </div>

    <div class="section">
        <h2>Solving the wave equation</h2>
        <hr>
        <p>
            In the time domain, Siren succeeds to solve the wave equation, while a Tanh-based architecture fails to discover the
            correct solution.
        </p>
        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="" class="gif">
            <source src="img/wave_combined_pad_label.mp4" type="video/mp4">
        </video>
    </div>

    <div class="section">
        <!-- <h2>Related Projects</h2>
        <hr>
        <p>
            Check out our related projects on the topic of implicit neural representations! <br>
        </p>
        <div class='row vspace-top'>
            <div class="col-sm-3">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/metasdf_steps_comp.mp4" type="video/mp4">
                </video>
            </div>

            <div class="col">
                <div class='paper-title'>
                    <a href="http://vsitzmann.github.io/metasdf/">MetaSDF: Meta-learning Signed Distance Functions</a>
                </div>
                <div>
                    We identify a key relationship between generalization across implicit neural representations and meta-
                    learning, and propose to leverage gradient-based meta-learning for learning priors over deep signed distance
                    functions. This allows us to reconstruct SDFs an order of magnitude faster than the auto-decoder framework,
                    with no loss in performance!
                </div>
            </div>
        </div>

        <div class='row vspace-top'>
            <div class="col-sm-3">
                <img src='img/SRNs.gif' class='img-fluid'>
            </div>

            <div class="col">
                <div class='paper-title'>
                    <a href="http://vsitzmann.github.io/srns/">Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations</a>

                </div>
                <div>
                    A continuous, 3D-structure-aware neural scene representation that encodes both geometry and appearance,
                    supervised only in 2D via a neural renderer, and generalizes for 3D reconstruction from a single posed 2D image.
                </div>
            </div>
        </div>

        <div class='row vspace-top'>
            <div class="col-sm-3">
                <img src='img/srn_seg_repimage.jpg' class='img-fluid'>
            </div>

            <div class="col">
                <div class='paper-title'>
                    <a href="https://www.computationalimaging.org/publications/semantic-srn/">Inferring Semantic Information with 3D Neural Scene Representations
                    </a>
                </div>
                <div>
                    We demonstrate that the features learned by neural implicit scene representations are useful for downstream
                    tasks, such as semantic segmentation, and propose a model that can learn to perform continuous 3D
                    semantic segmentation on a class of objects (such as chairs) given only a single, 2D (!) semantic label map!
                </div>
            </div>
        </div> -->

    <div class="section">
        <h2>References</h2>
        <hr>
        <div>
            <div class="list-group">
                <a href="https://users.cs.duke.edu/~tomasi/papers/phillips/phillips3DIM07.pdf"
                   class="list-group-item">
                    <!-- <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;"> -->
                </a>
            </div>
        </div>
    </div>

    <!-- <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
            @inproceedings{sitzmann2019siren,
                author = {Sitzmann, Vincent
                          and Martel, Julien N.P.
                          and Bergman, Alexander W.
                          and Lindell, David B.
                          and Wetzstein, Gordon},
                title = {Implicit Neural Representations
                          with Periodic Activation Functions},
                booktitle = {Proc. NeurIPS},
                year={2020}
            }
        </div>
    </div> -->

    <hr>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
